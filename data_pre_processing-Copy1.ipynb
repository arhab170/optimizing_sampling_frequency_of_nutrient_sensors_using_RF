{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84484c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pylab\n",
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "import plotly.express as px\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import jupyternotify\n",
    "ip = get_ipython()\n",
    "ip.register_magics(jupyternotify.JupyterNotifyMagics)\n",
    "from  sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.svm import SVR\n",
    "import dateutil\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from mlxtend.evaluate import PredefinedHoldoutSplit\n",
    "import kneed\n",
    "import kaleido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2828a7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41b5e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "station = \"erlabrunn\"\n",
    "flow_station = \"erlabrunn\"\n",
    "start = \"2016-11-15\"\n",
    "end = \"2020-12-30\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "c0b81a6c",
   "metadata": {},
   "source": [
    "station = \"kahl\"\n",
    "flow_station = \"steinbach\"\n",
    "start = \"2017-09-16\"\n",
    "end = \"2021-08-31\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f59a94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OPTIONS:  \"OPO4P\", \"NO3N\", \"NH4N\", \"TRP\"\n",
    "predict = \"OPO4P\"\n",
    "# OPTIONS: \"lr\", \"rf\", \n",
    "test_model = \"rf\"\n",
    "\n",
    "results = pd.DataFrame([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e972ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_model == \"rf\":\n",
    "    algo = RandomForestRegressor(n_jobs = -1)\n",
    "elif test_model == \"lr\":\n",
    "    algo = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f91320d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('all_data_%s.csv' %(station))\n",
    "df['Datum'] = pd.to_datetime(df['Datum'])\n",
    "df= df.set_index(\"Datum\")\n",
    "df = df.round(2)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d09289",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow = pd.read_csv(\"flow_%s.csv\" %(flow_station))\n",
    "flow['Datum'] = pd.to_datetime(flow['Datum'])\n",
    "flow= flow.set_index(\"Datum\")\n",
    "flow = flow.loc[start:end]\n",
    "df = pd.concat([df, flow], axis=1)\n",
    "df = df.dropna(thresh = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131d6223",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('%s_total.csv' % station)\n",
    "if station == \"kahl\":\n",
    "    if predict == \"OPO4P\" or predict == \"NH4N\":\n",
    "        df = df.loc[\"2019-09-02\":]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb5a0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdda77de",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pre_count = count(df, \"Pre Count\")\n",
    "\n",
    "df = df[[\"O2\", \"Temp\", \"Conduct\", \"pH\", \"flow\", predict]]         \n",
    "df = df.dropna(subset=[predict])\n",
    "\n",
    "Post_count = count(df, \"Post Count\")\n",
    "\n",
    "columns = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1996b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_data = Data_count(Pre_count, Post_count)\n",
    "print(station)\n",
    "Final_data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb96582",
   "metadata": {},
   "source": [
    "### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e407c35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ONLY FOR ERLABRUNN TO CLEAR PHOSPHATE A BIT\n",
    "if station == \"erlabrunn\":\n",
    "    df.loc[\"2018-07-02 09:45:00\", \"Conduct\"] = np.nan\n",
    "    df.loc[\"2018-08-20 09:30:00\", \"Conduct\"] = np.nan\n",
    "    df.loc[\"2018-08-20 09:45:00\", \"Conduct\"] = np.nan\n",
    "    df.loc[\"2018-12-17 11:30:00\", \"Conduct\"] = np.nan\n",
    "    \n",
    "    if predict == \"OPO4P\":\n",
    "        para = \"OPO4P\"\n",
    "        temp = df[[para]]\n",
    "        df= df.drop([para],axis =1)\n",
    "        temp = temp[(temp[para] < 0.3)]   \n",
    "        df = pd.concat([df, temp], axis=1)\n",
    "        df = df.loc[\"2019-01-01 00:00:00\":]\n",
    "        \n",
    "        \n",
    "    if predict == \"NO3N\":\n",
    "        df.loc[\"2020-11-24 08:30:00\", \"NO3N\"] = np.nan\n",
    "        \n",
    "    if predict == \"NH4N\":\n",
    "        df['NH4N'].mask(df['NH4N'].between(-0.8, 0.001), inplace=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16323a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if station == \"kahl\":\n",
    "    # Conduct cleaning\n",
    "    df.loc[\"2019-09-06 07:30:00\", \"Conduct\"] = np.nan\n",
    "    df.loc[\"2019-09-10 13:30:00\", \"Conduct\"] = np.nan\n",
    "    df.loc[\"2019-10-25 07:45:00\", \"Conduct\"] = np.nan\n",
    "    df.loc[\"2021-07-23 03:15:00\", \"Conduct\"] = np.nan\n",
    "    df.loc[\"2021-08-27 08:00:00\", \"Conduct\"] = np.nan\n",
    "    df.loc[\"2017-11-16\": \"2017-11-22\", \"Conduct\"] = np.nan\n",
    "    df.loc[\"2019-08-19 10:15:00\", \"Conduct\"] = np.nan\n",
    "    df.loc[\"2019-08-29 10:00:00\", \"Conduct\"] = np.nan\n",
    "    df.loc[\"2019-08-30 08:00:00\", \"Conduct\"] = np.nan\n",
    "    df.loc[\"2019-06-04 12:30:00\", \"Conduct\"] = np.nan\n",
    "    \n",
    "    df['Conduct'].mask(df['Conduct'].between(0, 350), inplace=True)\n",
    "    \n",
    "    #Temp Cleaning\n",
    "    df.loc[\"2017-11-17\": \"2017-11-21\", \"Temp\"] = np.nan\n",
    "    df.loc[\"2018-04-02\", \"Temp\"] = np.nan\n",
    "    df.loc[\"2019-05-21 09:30:00\": \"2019-05-23 23:45:00\", \"Temp\"] = np.nan\n",
    "    \n",
    "    #O2 Cleaning\n",
    "    df.loc[\"2017-11-16 09:15:00\": \"2017-11-16 23:45:00\", \"O2\"] = np.nan\n",
    "    df.loc[\"2019-05-21 09:30:00\": \"2019-05-23 23:45:00\", \"O2\"] = np.nan\n",
    "    \n",
    "    #NO3N cleaning\n",
    "    if predict == \"NO3N\":\n",
    "        df['NO3N'].mask(df['NO3N'].between(-1, 2), inplace=True)\n",
    "        df.loc[\"2021-08-27 08:30:00\", \"NO3N\"] = np.nan\n",
    "    \n",
    "    #NH4N cleaning\n",
    "    if predict == \"NH4N\":\n",
    "        df.loc[\"2019-05-27 10:15:00\", \"NH4N\"] = np.nan\n",
    "        df['NH4N'].mask(df['NH4N'].between(0.5, 40), inplace=True)\n",
    "        df['NH4N'].mask(df['NH4N'].between(-0.8, 0.001), inplace=True)\n",
    "    \n",
    "    #OPO4P cleaning\n",
    "    if predict == \"OPO4P\":\n",
    "        df['OPO4P'].mask(df['OPO4P'].between(0.25, 5), inplace=True)\n",
    "        df['OPO4P'].mask(df['OPO4P'].between(-0.8, 0.001), inplace=True)\n",
    "        df.loc[\"2019-08-07 16:15:00\", \"OPO4P\"] = np.nan\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531eebc7",
   "metadata": {},
   "source": [
    "##### add removal , remove anomaly rows and create a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8448142c",
   "metadata": {},
   "outputs": [],
   "source": [
    "removal = 0.1\n",
    "from sklearn.ensemble import IsolationForest\n",
    "clf=IsolationForest(n_estimators=100, max_samples='auto', contamination=float(removal), \\\n",
    "                        max_features=1.0, bootstrap=False, n_jobs=-1, random_state=42, verbose=0)\n",
    "clf.fit(df)\n",
    "pred = clf.predict(df)\n",
    "df['anomaly']=pred\n",
    "outliers=df.loc[df['anomaly']==-1]\n",
    "outlier_index=list(outliers.index)\n",
    "#print(outlier_index)\n",
    "#Find the number of anomalies and normal points here points classified -1 are anomalous\n",
    "print(df['anomaly'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef7472a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0bb77b59",
   "metadata": {},
   "source": [
    "### Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fbc976",
   "metadata": {},
   "outputs": [],
   "source": [
    "bef_interpol = df\n",
    "df = df.interpolate(limit = 30)\n",
    "df = df.dropna()\n",
    "df = df.round(2)\n",
    "df.to_csv(r'%s_cleaned_interpolated.csv' %station, index = True, header = True)\n",
    "#     print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a313033",
   "metadata": {},
   "source": [
    "### Time as a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb105ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()\n",
    "df[\"Month\"] = df['Datum'].dt.month\n",
    "df['month_sin'] = np.sin(2 * np.pi * df['Month']/12)\n",
    "df['month_cos'] = np.cos(2 * np.pi * df['Month']/12)\n",
    "\n",
    "df['week_number'] = df[\"Datum\"].dt.isocalendar().week\n",
    "df[\"week_sin\"] = np.sin(2 * np.pi * df[\"week_number\"] / df[\"week_number\"].max())\n",
    "df[\"week_cos\"] = np.cos(2 * np.pi * df[\"week_number\"] / df[\"week_number\"].max())\n",
    "df= df.drop([\"Month\", \"week_number\"],axis =1)\n",
    "df = df.set_index(\"Datum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a858f5",
   "metadata": {},
   "source": [
    "### Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e36d063",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformation\n",
    "if station == \"enborne\" and cleaning_model == 'lr':\n",
    "    df['log_Turb'] = np.exp(df['turb'])\n",
    "    df['log_Chlorophyll'] = np.power(df['Chlorophyll'], 0.5)\n",
    "    df['log_O2'] = np.power(df['O2'], 3)\n",
    "    df['log_flow'] = np.log(df['flow'])\n",
    "    df['Cube_Conduct']=np.power((df['Conduct']),3)\n",
    "    \n",
    "    df = df.drop([\"turb\", \"Chlorophyll\", \"O2\", \"flow\", \"Conduct\"],axis =1)\n",
    "    df.to_csv(r'%s_transformed.csv' %station, index = True, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213f2d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "before_transform = df\n",
    "if station == \"kahl\" or station == \"erlabrunn\":  \n",
    "    if cleaning_model == \"lr\":\n",
    "        df['log_flow'] = np.log(df['flow'])\n",
    "        df['log_Conduct']= np.log(df['Conduct'])\n",
    "        \n",
    "        df = df.drop([\"flow\", \"Conduct\"],axis =1)\n",
    "        df.to_csv(r'%s_transformed.csv' %station, index = True, header = True)\n",
    "after_transform = df\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4dde5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f692d69",
   "metadata": {},
   "source": [
    "### Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f39402",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=df.columns\n",
    "corr = df.corr()\n",
    "corr = corr.loc[:,[predict]]\n",
    "corr = corr.iloc[(-corr[predict].abs()).argsort()]\n",
    "if predict == \"NO3N\":\n",
    "    corr= corr.drop([\"NO3N\"],axis =0)\n",
    "\n",
    "if predict == \"OPO4P\":\n",
    "    corr= corr.drop([\"OPO4P\"],axis =0)\n",
    "    \n",
    "if predict == \"NH4N\":\n",
    "    corr= corr.drop([\"NH4N\"],axis =0)\n",
    "    \n",
    "if predict == \"TRP\":\n",
    "    corr= corr.drop([\"TRP\", \"NO3N\"],axis =0)\n",
    "print(corr)\n",
    "corr_order = list(corr.index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

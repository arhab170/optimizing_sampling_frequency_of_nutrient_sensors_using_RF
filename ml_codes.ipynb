{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcb768e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pylab\n",
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "import plotly.express as px\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import jupyternotify\n",
    "ip = get_ipython()\n",
    "ip.register_magics(jupyternotify.JupyterNotifyMagics)\n",
    "from  sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "raw",
   "id": "778c90f6",
   "metadata": {},
   "source": [
    "station = \"enborne\"\n",
    "flow_station = \"enbronn\"\n",
    "start = \"2016-11-14 11:45:00\"\n",
    "end = \"2020-12-31 00:00:00\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "759b70f0",
   "metadata": {},
   "source": [
    "station = \"erlabrunn\"\n",
    "flow_station = \"erlabrunn\"\n",
    "start = \"2016-11-15\"\n",
    "end = \"2020-12-30\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956f848f",
   "metadata": {},
   "outputs": [],
   "source": [
    "station = \"kahl\"\n",
    "flow_station = \"steinbach\"\n",
    "start = \"2017-09-16\"\n",
    "end = \"2021-08-31\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5072f12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('%sall_data_%s.csv' %(path, station))\n",
    "df['Datum'] = pd.to_datetime(df['Datum'])\n",
    "df= df.set_index(\"Datum\")\n",
    "df = df.round(2)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897e7675",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('%s_total.csv' % station)\n",
    "if station == \"kahl\":\n",
    "    if predict == \"OPO4P\" or predict == \"NH4N\":\n",
    "        df = df.loc[\"2019-09-02\":]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2ce1b2",
   "metadata": {},
   "source": [
    "### Machine Learning Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d899adea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if station == \"kahl\" or station == \"erlabrunn\":\n",
    "list_feat = columns.drop(predict)\n",
    "features = df[list_feat]\n",
    "number_of_features = len(features.columns)\n",
    "col_dict = column_dict(features)\n",
    "# features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4eb9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = df[[predict]]\n",
    "# label = np.array(df[[predict]])  \n",
    "# label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b1f6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "if station == \"enborne\":\n",
    "    major_X, minor_X, major_y, minor_y = train_test_split(features, label, stratify=label, shuffle=True, test_size=0.1)\n",
    "elif station == \"kahl\" or station == \"erlabrunn\":\n",
    "    major_X = features \n",
    "    major_y = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f84500",
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2(x,y):\n",
    "    zx = (x-np.mean(x))/np.std(x, ddof=1)\n",
    "    zy = (y-np.mean(y))/np.std(y, ddof=1)\n",
    "    r = np.sum(zx*zy)/(len(x)-1)\n",
    "    r2 = pow(r, 2)\n",
    "    return r2\n",
    "\n",
    "scorer_r2 = make_scorer(r2, greater_is_better=True)\n",
    "    \n",
    "\n",
    "def Adj_r2(x,y, major_X):\n",
    "    zx = (x-np.mean(x))/np.std(x, ddof=1)\n",
    "    zy = (y-np.mean(y))/np.std(y, ddof=1)\n",
    "    r = np.sum(zx*zy)/(len(x)-1)\n",
    "    r2 = pow(r, 2)\n",
    "    \n",
    "    # major_X.shape[1] gives to number of features that were used to make the prediction\n",
    "    return 1 - ((1-r2) * (len(x)-1)/(len(x)-major_X.shape[1]-1))\n",
    "\n",
    "\n",
    "# x = major_X\n",
    "scorer_adj_r2 = make_scorer(Adj_r2, greater_is_better=True, major_X = major_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f4cf45",
   "metadata": {},
   "source": [
    "# Rough for the ultimate cheating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8da5dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df[list_feat]\n",
    "label = df[[predict]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0945c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = blank_dataframe(features, predict)\n",
    "cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1d2af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(features)\n",
    "y = np.array(label)\n",
    "\n",
    "arr_r2 = []\n",
    "arr_RMSE = []\n",
    "\n",
    "# rf = RandomForestRegressor(n_jobs = -1)\n",
    "linear = linear_model.LinearRegression()\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test, y_train, y_test = X[train_index], X[test_index], y[train_index], y[test_index]\n",
    "    linear.fit(X_train, y_train.ravel())\n",
    "    predictions = linear.predict(X_test)\n",
    "    \n",
    "    \n",
    "    feats = pd.DataFrame(X_test, columns = list_feat)\n",
    "    lab_OG = pd.DataFrame(y_test, columns = [predict])\n",
    "    lab_pd = pd.DataFrame(predictions, columns=[\"pd_\" + predict])\n",
    "    \n",
    "    main =  pd.concat([feats, lab_OG, lab_pd], axis=1)\n",
    "    cleaned_df = pd.concat([cleaned_df, main], axis = 0)\n",
    "    \n",
    "    temp = r2_score(y_test, predictions)\n",
    "    arr_r2.append(temp)\n",
    "\n",
    "\n",
    "    temp2 = mean_squared_error(y_test, predictions, squared=False)\n",
    "    arr_RMSE.append(temp2)\n",
    "    \n",
    "r2 = np.average(arr_r2)\n",
    "rmse = np.average(arr_RMSE)\n",
    "\n",
    "print(\"Cross Validation results \\n\")\n",
    "print(\"Rsquared\", predict, \"\\n\", r2)\n",
    "print('RMSE ', predict, '\\n', rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2312b4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = comp_cleaned_df(features, cleaned_df)\n",
    "ss[\"cond\"] = pow(ss[(predict)] - ss[(\"pd_\"+ predict)],2)\n",
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb25992",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = ss[ss.cond < ss.cond.quantile(removal)]\n",
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e53458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_feat = ['O2', 'Temp', 'log_Conduct', 'pH', 'month_sin', 'month_cos', 'week_sin','week_cos', 'log_flow']\n",
    "list_feat = ['O2', 'Temp', 'log_Conduct', 'pH', 'month_sin', 'month_cos', 'week_sin','week_cos','log_flow']\n",
    "features = ss[list_feat]\n",
    "label = ss[[predict]]\n",
    "\n",
    "X = np.array(features)\n",
    "y = np.array(label)\n",
    "\n",
    "arr_r2 = []\n",
    "arr_RMSE = []\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test, y_train, y_test = X[train_index], X[test_index], y[train_index], y[test_index]\n",
    "    linear = linear_model.LinearRegression()\n",
    "    linear.fit(X_train, y_train)\n",
    "    predictions = linear.predict(X_test)\n",
    "    \n",
    "    \n",
    "#     feats = pd.DataFrame(X_test, columns = list_feat)\n",
    "#     lab_OG = pd.DataFrame(y_test, columns = [predict])\n",
    "#     lab_pd = pd.DataFrame(predictions, columns=[\"pd_\" + predict])\n",
    "    \n",
    "#     main =  pd.concat([feats, lab_OG, lab_pd], axis=1)\n",
    "#     cleaned_df = pd.concat([cleaned_df, main], axis = 0)\n",
    "    \n",
    "    temp = r2_score(y_test, predictions)\n",
    "    arr_r2.append(temp)\n",
    "\n",
    "\n",
    "    temp2 = mean_squared_error(y_test, predictions, squared=False)\n",
    "    arr_RMSE.append(temp2)\n",
    "    \n",
    "r2 = np.average(arr_r2)\n",
    "rmse = np.average(arr_RMSE)\n",
    "\n",
    "print(\"Cross Validation results \\n\")\n",
    "print(\"Rsquared\", predict, \"\\n\", r2)\n",
    "print('RMSE ', predict, '\\n', rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79453856",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b28b65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ss[list_feat]\n",
    "label = ss[[predict]]\n",
    "\n",
    "X = np.array(features)\n",
    "y = np.array(label)\n",
    "\n",
    "arr_r2 = []\n",
    "arr_RMSE = []\n",
    "\n",
    "rf = RandomForestRegressor(n_jobs = -1)\n",
    "    \n",
    "kf = KFold(n_splits=5)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test, y_train, y_test = X[train_index], X[test_index], y[train_index], y[test_index]\n",
    "    rf.fit(X_train,  y_train.ravel())\n",
    "    predictions = rf.predict(X_test)\n",
    "    \n",
    "    \n",
    "#     feats = pd.DataFrame(X_test, columns = list_feat)\n",
    "#     lab_OG = pd.DataFrame(y_test, columns = [predict])\n",
    "#     lab_pd = pd.DataFrame(predictions, columns=[\"pd_\" + predict])\n",
    "    \n",
    "#     main =  pd.concat([feats, lab_OG, lab_pd], axis=1)\n",
    "#     cleaned_df = pd.concat([cleaned_df, main], axis = 0)\n",
    "    \n",
    "    temp = r2_score(y_test, predictions)\n",
    "    arr_r2.append(temp)\n",
    "\n",
    "\n",
    "    temp2 = mean_squared_error(y_test, predictions, squared=False)\n",
    "    arr_RMSE.append(temp2)\n",
    "    \n",
    "r2 = np.average(arr_r2)\n",
    "rmse = np.average(arr_RMSE)\n",
    "\n",
    "print(\"Cross Validation results \\n\")\n",
    "print(\"Rsquared\", predict, \"\\n\", r2)\n",
    "print('RMSE ', predict, '\\n', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f10aeb",
   "metadata": {},
   "source": [
    "# Rough ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aecf1fa",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "raw",
   "id": "acb284d3",
   "metadata": {},
   "source": [
    "if linear_regression == 1:\n",
    "    lr = linear_model.LinearRegression()\n",
    "\n",
    "    X = np.array(major_X[list_feat])\n",
    "    y = np.array(major_y)\n",
    "    \n",
    "    sfs = SFS(lr, \n",
    "              k_features=number_of_features, \n",
    "              forward=True, \n",
    "              floating=False, \n",
    "              scoring= scorer_rmse,\n",
    "              cv=5)\n",
    "    sfs = sfs.fit(X, y.ravel())\n",
    "    \n",
    "    fig = plot_sfs(sfs.get_metric_dict(), kind='std_err')\n",
    "    plt.title(\"RMSE %s %s\" % (predict, station))\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5f84a21e",
   "metadata": {},
   "source": [
    "if linear_regression == 1:\n",
    "    results = pd.DataFrame.from_dict(sfs.get_metric_dict()).T\n",
    "results"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9302c6c7",
   "metadata": {},
   "source": [
    "if linear_regression == 1:\n",
    "    lr = linear_model.LinearRegression()\n",
    "\n",
    "    X = np.array(major_X[list_feat])\n",
    "    y = np.array(major_y)\n",
    "    \n",
    "    sfs = SFS(lr, \n",
    "              k_features=number_of_features, \n",
    "              forward=True, \n",
    "              floating=False, \n",
    "              scoring= sklearn_r2,\n",
    "              cv=5)\n",
    "    \n",
    "    sfs = sfs.fit(X, y.ravel())\n",
    "    \n",
    "    fig = plot_sfs(sfs.get_metric_dict(), kind='std_err')\n",
    "    plt.title(\"Sklearn R squared %s %s\" % (predict, station))\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "75cc324a",
   "metadata": {},
   "source": [
    "if linear_regression == 1:\n",
    "    results = pd.DataFrame.from_dict(sfs.get_metric_dict()).T\n",
    "results"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d3326196",
   "metadata": {},
   "source": [
    "if linear_regression == 1:\n",
    "    pd.DataFrame(main_adj_r2).plot(title = \"Adjusted R squared %s\" %predict)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1b89a2da",
   "metadata": {},
   "source": [
    "if linear_regression == 1:\n",
    "    pd.DataFrame(main_rmse).plot(title = \"RMSE %s\" %predict)\n",
    "    print(main_rmse)\n",
    "    print(corr_order)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "40ba97b5",
   "metadata": {},
   "source": [
    "if linear_regression == 1:\n",
    "    figx = px.line(pd_concat, x=pd_concat.index, y=pd_concat.columns[:], title = \"%s %s\" % (predict, station) )\n",
    "    figx.update_xaxes(rangeslider_visible = True)\n",
    "    figx.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f154b82",
   "metadata": {},
   "source": [
    "### grid search"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5a945102",
   "metadata": {},
   "source": [
    "# Original Grid\n",
    "if linear_regression == 0 and grid_search ==1:\n",
    "    # Number of trees in random forest\n",
    "    n_estimators = [50]\n",
    "    # Method of selecting samples for training each tree\n",
    "    bootstrap = [True, False]\n",
    "    # Number of features to consider at every split\n",
    "    max_features = ['auto', 'sqrt']\n",
    "    # Maximum number of levels in tree\n",
    "    max_depth = [20, 40, 60, 80, 100, 120]\n",
    "    # Minimum number of samples required to split a node\n",
    "    min_samples_split = [6, 12, 18]\n",
    "    # Minimum number of samples required at each leaf node\n",
    "    min_samples_leaf = [6, 12, 18]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3518867b",
   "metadata": {},
   "source": [
    "# Filtered Grid\n",
    "if linear_regression == 0 and grid_search ==1:\n",
    "    # Number of trees in random forest\n",
    "    n_estimators = [50, 100]\n",
    "    # Method of selecting samples for training each tree\n",
    "    bootstrap = [True]\n",
    "    # Number of features to consider at every split\n",
    "    max_features = ['sqrt']\n",
    "    # Maximum number of levels in tree\n",
    "    max_depth = [80, 100, 120, 140]\n",
    "    # Minimum number of samples required to split a node\n",
    "    min_samples_split = [9,18,20]\n",
    "    # Minimum number of samples required at each leaf node\n",
    "    min_samples_leaf = [27, 30, 33]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6197b03c",
   "metadata": {},
   "source": [
    "if linear_regression == 0 and grid_search ==1:\n",
    "# Create the param grid\n",
    "    param_grid = {'n_estimators': n_estimators,\n",
    "                   'max_features': max_features,\n",
    "                   'max_depth': max_depth,\n",
    "                   'min_samples_split': min_samples_split,\n",
    "                   'min_samples_leaf': min_samples_leaf,\n",
    "                   'bootstrap': bootstrap}\n",
    "    print(param_grid)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ea06d99e",
   "metadata": {},
   "source": [
    "if linear_regression == 0 and grid_search ==1:\n",
    "    rf = RandomForestRegressor()\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    rf_Grid = GridSearchCV(estimator = rf, param_grid = param_grid, cv = 5, verbose=2, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "69f04a0f",
   "metadata": {},
   "source": [
    "%%time\n",
    "if linear_regression == 0 and grid_search ==1:\n",
    "    rf_Grid.fit(major_X, major_y)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e925acb4",
   "metadata": {},
   "source": [
    "if linear_regression == 0 and grid_search ==1:\n",
    "    best = rf_Grid.best_params_\n",
    "    print(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbf13ae",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e6ee1039",
   "metadata": {},
   "source": [
    "if linear_regression == 0:\n",
    "#     %%notify\n",
    "#     %%time\n",
    "    temp_feats = []\n",
    "    main_adj_r2 = []\n",
    "    main_rmse = []\n",
    "    \n",
    "    rf = RandomForestRegressor(bootstrap = best.get('bootstrap'), max_depth= best.get('max_depth'),\n",
    "                               max_features= best.get(\"max_features\"), \n",
    "                               min_samples_leaf= best.get(\"min_samples_leaf\"),\n",
    "                               min_samples_split = best.get(\"min_samples_split\") , \n",
    "                               n_estimators=100, n_jobs = -1)\n",
    "    \n",
    "     #for NO3    \n",
    "    # corr_order = [\"Conduct\", \"pH\", \"flow\", \"Temp\", \"O2\", \"turb\", \"Chlorophyll\"]\n",
    "\n",
    "    #for TRP\n",
    "    corr_order  = [\"Conduct\", \"flow\", \"Temp\", \"turb\", \"pH\", \"O2\", \"Chlorophyll\"]\n",
    "\n",
    "    for i in corr_order:\n",
    "        temp_feats.append(i)\n",
    "        if k_fold == 1:\n",
    "\n",
    "            X = np.array(major_X[temp_feats])\n",
    "            y = np.array(major_y)\n",
    "\n",
    "            arr_Adj_r2 = []\n",
    "            arr_RMSE = []\n",
    "\n",
    "            kf = KFold(n_splits=5)\n",
    "            for train_index, test_index in kf.split(X):\n",
    "                X_train, X_test, y_train, y_test = X[train_index], X[test_index], y[train_index], y[test_index]\n",
    "                rf.fit(X_train, y_train.ravel())\n",
    "                predictions = rf.predict(X_test)\n",
    "                pd_predictions = pd.DataFrame(predictions, columns=[\"predicted\"])\n",
    "                pd_observed = pd.DataFrame(y_test, columns=[\"observed\"])\n",
    "                pd_concat = pd.concat([pd_observed, pd_predictions], axis=1)\n",
    "\n",
    "    #             temp = Adj_r2(y_test, predictions, X_test)\n",
    "    #             arr_Adj_r2.append(temp)\n",
    "\n",
    "\n",
    "                temp2 = mean_squared_error(y_test, predictions, squared=False)\n",
    "                arr_RMSE.append(temp2)\n",
    "    #             print(arr_RMSE)\n",
    "\n",
    "\n",
    "\n",
    "    #         adj_r2 = np.average(arr_Adj_r2)\n",
    "    #         main_adj_r2.append(adj_r2)\n",
    "            rmse = np.average(arr_RMSE)\n",
    "            main_rmse.append(rmse)\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "be44845a",
   "metadata": {},
   "source": [
    "if linear_regression == 0:\n",
    "    pd.DataFrame(main_rmse).plot(title = \"RMSE %s %s\" % (predict, station))\n",
    "    print(main_rmse)\n",
    "    print(corr_order)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8f4dfd88",
   "metadata": {},
   "source": [
    "#### RMSE"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0576196a",
   "metadata": {},
   "source": [
    "%%notify\n",
    "%%time\n",
    "if linear_regression == 0:\n",
    "\n",
    "    rf = RandomForestRegressor(bootstrap = True, max_depth= 20,\n",
    "                               max_features= \"sqrt\", \n",
    "                               min_samples_leaf= 12,\n",
    "                               min_samples_split = 20 , \n",
    "                               n_estimators=200, n_jobs = -1)\n",
    "    \n",
    "\n",
    "    X = np.array(major_X[list_feat])\n",
    "    y = np.array(major_y)\n",
    "\n",
    "    sfs = SFS(rf, \n",
    "              k_features=number_of_features, \n",
    "              forward=True, \n",
    "              floating=False, \n",
    "              scoring= scorer_rmse,\n",
    "              cv=5)\n",
    "    sfs = sfs.fit(X, y.ravel())\n",
    "    \n",
    "    fig = plot_sfs(sfs.get_metric_dict(), kind='std_err')\n",
    "    plt.title(\"RMSE %s %s\" % (predict, station))\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4cef1a18",
   "metadata": {},
   "source": [
    "if linear_regression == 0:\n",
    "    results = pd.DataFrame.from_dict(sfs.get_metric_dict()).T\n",
    "results"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f30e5e28",
   "metadata": {},
   "source": [
    "#### R squared"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5a16747c",
   "metadata": {},
   "source": [
    "%%notify\n",
    "%%time\n",
    "if linear_regression == 0:\n",
    "#     rf = RandomForestRegressor(bootstrap = best.get('bootstrap'), max_depth= best.get('max_depth'),\n",
    "#                                max_features= best.get(\"max_features\"), \n",
    "#                                min_samples_leaf= best.get(\"min_samples_leaf\"),\n",
    "#                                min_samples_split = best.get(\"min_samples_split\") , \n",
    "#                                n_estimators=200, n_jobs = -1)\n",
    "\n",
    "    rf = RandomForestRegressor(n_jobs = -1)\n",
    "    \n",
    "    X = np.array(major_X[list_feat])\n",
    "    y = np.array(major_y)\n",
    "\n",
    "    sfs = SFS(rf,\n",
    "              k_features=(number_of_features), \n",
    "              forward=True, \n",
    "              floating=False, \n",
    "              scoring= sklearn_r2,\n",
    "              cv=5)\n",
    "    sfs = sfs.fit(X, y.ravel())\n",
    "    \n",
    "    fig = plot_sfs(sfs.get_metric_dict(), kind='std_err')\n",
    "    plt.title(\"SK R squared %s %s\" % (predict, station))\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "7419343d",
   "metadata": {},
   "source": [
    "if linear_regression == 0:\n",
    "    results = pd.DataFrame.from_dict(sfs.get_metric_dict()).T\n",
    "results"
   ]
  },
  {
   "cell_type": "raw",
   "id": "97a4d6e1",
   "metadata": {},
   "source": [
    "order = order_of_features(results, col_dict)\n",
    "order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3664fc4",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "raw",
   "id": "11d1ea3f",
   "metadata": {},
   "source": [
    "%%notify\n",
    "%%time\n",
    "if linear_regression == 2:\n",
    "    \n",
    "    rf = RandomForestRegressor(bootstrap = True, max_depth= 20,\n",
    "                               max_features= \"sqrt\", \n",
    "                               min_samples_leaf= 12,\n",
    "                               min_samples_split = 20 , \n",
    "                               n_estimators=200, n_jobs = -1)\n",
    "    \n",
    "    X = np.array(major_X[list_feat])\n",
    "    y = np.array(major_y)\n",
    "\n",
    "    sfs = SFS(rf, \n",
    "              k_features=(number_of_features), \n",
    "              forward=True, \n",
    "              floating=False, \n",
    "              scoring= scorer_adj_r2,\n",
    "              cv=5)\n",
    "    sfs = sfs.fit(X, y.ravel())\n",
    "    \n",
    "    fig = plot_sfs(sfs.get_metric_dict(), kind='std_err')\n",
    "    plt.title(\"Adjusted R squared %s %s\" % (predict, station))\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ff08bfb1",
   "metadata": {},
   "source": [
    "if linear_regression == 0:\n",
    "    results = pd.DataFrame.from_dict(sfs.get_metric_dict()).T\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a18d42f",
   "metadata": {},
   "source": [
    "### Others"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b5f647c5",
   "metadata": {},
   "source": [
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e98a230e",
   "metadata": {},
   "source": [
    "%%notify\n",
    "%%time\n",
    "if linear_regression == 2:\n",
    "    \n",
    "    MLP = MLPRegressor()\n",
    "    X = np.array(major_X[list_feat])\n",
    "    y = np.array(major_y)\n",
    "\n",
    "    sfs = SFS(MLP, \n",
    "              k_features=(number_of_features), \n",
    "              forward=True, \n",
    "              floating=False, \n",
    "              scoring= sklearn_r2,\n",
    "              cv=5)\n",
    "    sfs = sfs.fit(X, y.ravel())\n",
    "    \n",
    "    fig = plot_sfs(sfs.get_metric_dict(), kind='std_err')\n",
    "    plt.title(\"sk R squared %s %s\" % (predict, station))\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9fdd07da",
   "metadata": {},
   "source": [
    "if linear_regression == 2:\n",
    "    results = pd.DataFrame.from_dict(sfs.get_metric_dict()).T\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac0fdbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
